# FROM https://github.com/GoranMilovanovic/OpenDataR/tree/master/TrafficAccidentsBGD2015
#' # Open Data Notebooks 2017-01 :: ODN2017-01
#' ## Case Study: Traffic Accidents in Belgrade 2015.
#' #### Data Set: OPENDATA_SNEZGODE_exc.csv
#' #### Source: [data.gov.rs](http://data.gov.rs)
#' #### Description: Traffic Accidents in Belgrade, 2015.
#' 
#' *** 
#' ![](../img/GoranSMilovanovic.jpg)
#' 
#' **Author:** [Goran S. Milovanovic](http//www.exactness.net), [Data Science Serbia](http//www.datascience.rs)
#' 
#' **Notebook:** 01/30/2017, Belgrade, Serbia
#' 
#' ![](../img/DataScienceSerbia_Logo.png)
#' 
#' ***
#' 
#' This notebook accompanied the first [Open Data R Meetup](https://www.meetup.com/BelgradeR/events/237202071/) in Belgrade, organized by [Data Science Serbia](http//www.datascience.rs) in [Startit Center](http://en.startit.rs/), Savska 5, Belgrade, 01/30/2017. The event took place to introduce the Data Science community in Serbia with the Open Data initative people, and celebrate the completion of the 2nd [Introduction to R for Data Science](https://github.com/GoranMilovanovic/Introduction-to-R-for-Data-Science) course that Data Science Serbia has provided in Startit, Belgrade. As of now, more than 45 people have learned - or are currently learning - to code in R for free, thanks to our efforts to develop the Introduction to R for Data Science course.
#' 
#' The notebook focuses on an exploratory analysis of the test open data set of Traffic Accidents in Belgrade in 2015, provided at the [Open Data Portal of the Republic of Serbia](http://data.gov.rs/sr/) *that is currently under development*. The data set was kindly provided to the Open Data Portal by the [Republic of Serbia Ministry of Interior](http://mup.gov.rs/wps/portal/en/!ut/p/z1/04_Sj9CPykssy0xPLMnMz0vMAfIjo8zi_S19zQzdDYy83c1cjQwcA80tXbxdLYwtPAz0wwkpiAJKG-AAjiD9UYSUFORGGKQ7KioCADcc2vk!/dz/d5/L0lJSkovd0RNQUJrQUVnQSEhLzRObEhVeEEhL1o2X085TTYxRzAySzhHSUUwQTY3R0pHR04yT00zL2Vu/). Many more open data sets will be indexed and uploaded in the forthcoming weeks and months. 
#' 
#' Besides focusing on the exploration and visualization of this test data set, we demonstrate the basic usage of [{weatherData}](https://cran.r-project.org/web/packages/weatherData/index.html) to fetch historical weather data to R, [{wbstats}](https://cran.r-project.org/web/packages/wbstats/index.html) to access the rich [World Data Bank](http://databank.worldbank.org/data/home.aspx) time series, and [{ISOcodes}](https://cran.r-project.org/web/packages/ISOcodes/) packages in R.
#' 
#' Some exploratory modeling (Negative Binomial Regression with `glm.nb()` and Ordinal Logistic Regression with `clm()` from [{ordinal}](https://cran.r-project.org/web/packages/ordinal/index.html)) is exercised merely to assess the *prima facie* effects of the most influential factors.
#' 
#' ***
#' 
#' **Disclaimer.** The [Open Data Portal of the Republic of Serbia](http://data.gov.rs/sr/) is a young initiative that is currently under development. Neither the owner of this GitHub account as an individual, or [Data Science Serbia](http//www.datascience.rs) as an organization, hold any responsibility for the changes in the URLs of the data sets, or the changes in the content of the data sets published on  the [Open Data Portal of the Republic of Serbia](http://data.gov.rs/sr/). The results of the exploratory analyses and statistical models that are presented on this GitHub account are developed for illustrative purposes only, having in mind the goal of popularization of Open Data exclusively. The owner of this GitHub account strongly advises to consult him (e-mail: [goran.s.milovanovic@gmail.com](mailto:goran.s.milovanovic@gmail.com) and [Data Science Serbia](http//www.datascience.rs) before using the results presented here in public debate or media, and/or for any purposes other than motivating the usage and development of Open Data.  
#' 
#' ***
#' 
#' ### 1. Setup
#' 
#' Load libraries + raw data:
#' 
## ----echo = T, message = F-----------------------------------------------
rm(list = ls())
library(dplyr)
library(tidyr)
library(ggplot2)
library(knitr)
library(ggmap)

### --- Working Directory
wDir <- '../TrafficAccidentsBGD2015'
setwd(wDir)

### --- Load Raw Data Set
fileLoc <- 'OPENDATA_SNEZGODE exc.csv'
rawData <- read.csv(fileLoc,
                    header = T,
                    check.names = F,
                    stringsAsFactors = F) 

### --- Inspect Data Set
dim(rawData)

#' 
#' Take a sneak peek at the data set:
#' 
## ----echo = T------------------------------------------------------------
glimpse(rawData)

#' 
#' What are we looking at:
#' 
## ----echo = T, message = F-----------------------------------------------
bgdMap <- get_map(location = 'Belgrade',
                  maptype = "roadmap")
ggmap(bgdMap, 
      extent = "device") + 
  geom_point(data = rawData,
             aes(x = WGS_X, y = WGS_Y), 
             size = .25, 
             color = "blue",
             alpha = .35) 

#' 
#' With 220 points found outisde of the Belgrade Google Map area we're already certain that some measurement error is present in the geolocalisation data. We'll take care of it later.
#' 
#' Let's take a quick look at the city core in a 2D density plot with `geom_density2d` from {ggplot2}:
#' 
## ----echo = T, message = F-----------------------------------------------
bgdMap <- get_map(location = 'Kneza Milosa, Belgrade',
                  maptype = "roadmap",
                  zoom = 16)
ggmap(bgdMap, 
      extent = "device") + 
  geom_density2d(data = rawData,
                 aes(x = WGS_X, y = WGS_Y),
                 size = .1) +
  stat_density2d(data = rawData,
                 aes(x = WGS_X, y = WGS_Y, 
                     fill = ..level.., 
                     alpha = ..level..), 
                 size = 0.01, 
                 bins = 16, 
                 geom = "polygon") + 
  scale_fill_gradient(low = "white", high = "blue") + 
  scale_alpha(range = c(0, 0.3), guide = FALSE) + 
  theme(legend.position="none")

#' 
## ----echo = T, message = F-----------------------------------------------
bgdMap <- get_map(location = 'Mostar, Belgrade',
                  maptype = "roadmap",
                  zoom = 16)
ggmap(bgdMap, 
      extent = "device") + 
  geom_density2d(data = rawData,
                 aes(x = WGS_X, y = WGS_Y),
                 size = .1) +
  stat_density2d(data = rawData, 
                 aes(x = WGS_X, y = WGS_Y, 
                     fill = ..level.., 
                     alpha = ..level..), 
                 size = 0.01, 
                 bins = 16, 
                 geom = "polygon") + 
  scale_fill_gradient(low = "white", high = "blue") + 
  scale_alpha(range = c(0, 0.3), guide = FALSE) +
  theme(legend.position="none")

#' 
#' Let's start figuring out the variables:
#' 
## ----echo = T------------------------------------------------------------
# - VRSTA_NEZ
unique(rawData$VRSTA_NEZ)

#' 
## ----echo = T------------------------------------------------------------
table(rawData$VRSTA_NEZ)

#' 
## ----echo = T------------------------------------------------------------
# - NAZIV_TIP
unique(rawData$NAZIV_TIP)

#' 
## ----echo = T------------------------------------------------------------
table(rawData$NAZIV_TIP)

#' 
## ----echo = T------------------------------------------------------------
# - NAZIV_DET
head(unique(rawData$NAZIV_DET))

#' 
## ----echo = T, results = 'asis'------------------------------------------
# - NAZIV_TIP vs. VRSTA_NEZ
kable(table(rawData$VRSTA_NEZ, rawData$NAZIV_TIP))

#' 
#' ***
#' 
#' ### 2. Data Wrangling: cleaning this up + some re-structuring for future use
#' 
#' Separate Date from Time:
#' 
## ----echo = T------------------------------------------------------------
# - Separate Date and Time
rawData <- separate(data = rawData,
                    col = VREME_NEZ,
                    into = c('Date', 'Time'),
                    sep = ',',
                    remove = F)

#' 
#' Separate Date to Day, Month, and Year:
#' 
## ----echo = T------------------------------------------------------------
# - Date --> Day, Month, Year
rawData <- separate(data = rawData,
                    col = Date,
                    into = c('Day', 'Month', 'Year'),
                    sep = '\\.',
                    remove = F)

#' 
#' Separate Time to Hour, Minute: 
#' 
## ----echo = T------------------------------------------------------------
# - Time --> Hour, Minute
rawData <- separate(data = rawData,
                    col = Time,
                    into = c('Hour', 'Minute'),
                    sep = ':',
                    remove = F)

#' 
#' Add a new Date-Time format:
#' 
## ----echo = T------------------------------------------------------------
# - New Date-Time format:
rawData$DateTime <- paste(
  paste(rawData$Month,
        rawData$Day,
        rawData$Year,
        sep = '/'),
  paste(rawData$Hour,
        rawData$Min,
        sep = ":"),
  sep = ", "
)

#' 
#' And check:
#' 
## ----echo = T------------------------------------------------------------
# - Check Data Set:
kable(table(rawData$Year, rawData$Month))

#' 
#' There are some data points labeled by '2013' and '2014'; probably errors; correct:
#' 
## ----echo = T------------------------------------------------------------
# - Year 2013, 2014: probably errors; correct
rawData[rawData$Year == '2014', 'Year'] <- '2015'
rawData[rawData$Year == '2013', 'Year'] <- '2015'

# - Check Data Set:
kable(table(rawData$Year, rawData$Month))

#' 
#' Very few data points for December; get rid of it:
#' 
## ----echo = T------------------------------------------------------------
# - December --> too few data points; drop:
rawData <- rawData[-which(rawData$Month == '12'), ]

#' 
#' And check:
#' 
## ----echo = T------------------------------------------------------------
# - Check Data Set:
kable(table(rawData$Year, rawData$Month))

#' 
#' What's this:
#' 
## ----echo = T------------------------------------------------------------
# - Outcome: from VRSTA_NEZ
unique(rawData$VRSTA_NEZ)

#' 
#' Recode:
#' 
## ----echo = T------------------------------------------------------------
rawData$Outcome <- factor(rawData$VRSTA_NEZ)
levels(rawData$Outcome) <- c('Damage', 'Death','Injury')
levels(rawData$Outcome)



#' 
#' Turn into an ordered factor (possible use: ordinal logistic)
#' 
## ----echo = T------------------------------------------------------------
# - Outcome as ordered factor
rawData$Outcome <- factor(rawData$Outcome, 
                       levels = c('Damage', 'Injury', 'Death'),
                       ordered = T)

#' 
#' What is this + recode:
#' 
## ----echo = T------------------------------------------------------------
# - Type: from NAZIV_TIP
unique(rawData$NAZIV_TIP)
rawData$Type <- factor(rawData$NAZIV_TIP)
levels(rawData$Type) <- c('None', 
                          '2VehTurnOrCross',
                          '2VehNoTurn',
                          '1Veh',
                          'parkedVeh',
                          'pedestrian')
levels(rawData$Type)

#' 
#' How many out of 12K+ recorded accidents were categorized:
#' 
## ----echo = T------------------------------------------------------------
# - how many accidents were categorized?
length(rawData$Type) - sum(rawData$Type == 'None')

#' 
#' Geography:
#' 
## ----echo = T------------------------------------------------------------
# - Lat, Lon
rawData$Lat <- rawData$WGS_Y
rawData$Lon <- rawData$WGS_X

# - Check Geographical Data
# - Belgrade is on: Coordinates: 44°49'N 20°28'E
# - source: https://en.wikipedia.org/wiki/Belgrade
range(rawData$Lon)

#' 
## ----echo = T------------------------------------------------------------
range(rawData$Lat)

#' 
#' Is this cool? Probably not. Keep only data points between $-3SD$ and $+3SD$.
#' N.B. This is not the right procedure to clean-up the data set. The correct procedure would involve having a vector map of Belgrade and then keeping only data points strictly found in the administratively defined region of interest.
#' 
## ----echo = T------------------------------------------------------------
# - filter
rawData <- rawData %>% 
  filter (Lon < mean(Lon) + 3*sd(Lon), 
          Lon > mean(Lon) -3*sd(Lon), 
          Lat < mean(Lat) + 3*sd(Lat), 
          Lat > mean(Lat) - 3*sd(Lat))

#' 
#' Sort:
#' 
## ----echo = T------------------------------------------------------------
# - Sort Data Set
rawData <- rawData[order(rawData$Day, 
                         rawData$Month,
                         rawData$Hour,
                         rawData$Minute), ]

#' 
#' `dataSet` will be the working data set:
#' 
## ----echo = T------------------------------------------------------------
### --- Working Data Set
dataSet <- rawData[, c('DateTime', 'Day', 'Month', 'Year',
                       'Time', 'Hour', 'Minute', 'Lat', 'Lon',
                       'Type', 'Outcome')]
rm(rawData)

#' 
#' Save:
#' 
## ----echo = T------------------------------------------------------------
### --- Save Working Data Set
### --- Working Directory
wDir <- '../TrafficAccidentsBGD2015'
setwd(wDir)
write.csv(dataSet, file = 'MUP2015_TrafficAccidentsBGD.csv')

#' 
#' ***
#' 
#' ### 3. Exploratory Data Analysis
#' 
#' Now, let's visualize properly w. `{leaflet}`:
#' 
#' #### Accident Density
#' 
#' The density of traffic accidents is dynamically represents by markers in the Leaflet map. Click or zoom in too discover fine-grained information.
#' 
## ----echo = T------------------------------------------------------------
library(leaflet)
# - add an HTML descriptive column to dataSet
dataSet$Description <- paste(
  '<b>Date: </b>', paste(dataSet$Month, dataSet$Day, dataSet$Year, sep = "/"), '<br>',
  '<b>Time: </b>', paste(dataSet$Hour, dataSet$Minute, sep = ":"), '<br>',
  '<b>Outcome: </b>', dataSet$Outcome,
  sep = '')

accMap <- leaflet() %>%
  addTiles() %>%
  addMarkers(lng = dataSet$Lon,
             lat= dataSet$Lat,
             popup = dataSet$Description, 
             clusterOptions = markerClusterOptions())
accMap

#' 
#' ***
#' 
#' #### Accident Severity
#' 
#' The severity of the traffic accident outcomes is represents by marker size and colors: yellow stands for 'Damage', orange for 'Injury', red for 'Death'. Click or zoom in too discover fine-grained information.
#' 
## ----echo = T------------------------------------------------------------
# - Add Outcome Color
dataSet$OutcomeColor <- dataSet$Outcome
dataSet$OutcomeColor <- recode(dataSet$OutcomeColor, 
                               Damage = 'Yellow',
                               Injury = 'DarkOrange',
                               Death = 'Red')
# - Add Outcome Warning (Marker Size)
dataSet$OutcomeWarning <- dataSet$Outcome
dataSet$OutcomeWarning <- recode(dataSet$OutcomeWarning, 
                                 Damage = '10',
                                 Injury = '15',
                                 Death = '20')
dataSet$OutcomeWarning <- as.numeric(dataSet$OutcomeWarning)
  
accMap <- leaflet() %>%
  addTiles(urlTemplate = "http://{s}.tiles.wmflabs.org/bw-mapnik/{z}/{x}/{y}.png", 
           attribution = '&copy; <a href="http://www.openstreetmap.org/copyright">OpenStreetMap</a>') %>% 
  addCircleMarkers(lng = dataSet$Lon,
                   lat= dataSet$Lat,
                   radius = dataSet$OutcomeWarning*2,
                   popup = dataSet$Description,
                   fill = T,
                   fillColor = dataSet$OutcomeColor,
                   stroke = F,
                   fillOpacity = .5)
accMap

#' 
#' ***
#' 
#' What was the probability of a traffic accident **resulting in injury** in Belgrade, 2015? N.B. That is the *conditional probability*, $P(Injury|Road Accident)$:
#' 
## ----echo = T------------------------------------------------------------
outcomes <- table(dataSet$Outcome)
pInjury <- outcomes['Injury']/sum(outcomes)
pInjury

#' 
#' That is some 25%:
#' 
## ----echo = T------------------------------------------------------------
pInjury*100

#' 
#' What was the probability of a traffic accident **with fatal consequences** in Belgrade, 2015? N.B. That is the *conditional probability*, $P(Fatal|Road Accident)$:
#' 
## ----echo = T------------------------------------------------------------
outcomes <- table(dataSet$Outcome)
pDeath <- unname(outcomes['Death']/sum(outcomes))
pDeath

#' 
#' which is less than a half percent:
#' 
## ----echo = T------------------------------------------------------------
pDeath*100

#' 
#' **Reminder:** We do not know what is the probability of being engaged in a traffic accident, so do not rush with associating emotional responses to these probabilities...
#' 
#' Accidents by months:
#' 
## ----echo = T------------------------------------------------------------
byMonth <- dataSet %>%
  group_by(Month) %>%
  summarise(Accidents = n())
byMonth$Month <- as.numeric(byMonth$Month)
# byMonth$Month <- factor(byMonth$Month, levels <- byMonth$Month)
ggplot(byMonth, aes(x = Month, y = Accidents)) + 
  geom_line(color = "blue", size = .5) + 
  geom_point(color = "blue", size = 1.5) + 
  geom_point(color = "white", size = 1) + 
  scale_x_continuous(breaks = byMonth$Month,
                   labels = month.abb[as.numeric(byMonth$Month)]) +
  ggtitle('Belgrade, 2015: Traffic Accidents by Month') +
  ylim(1000, max(byMonth$Accidents)+100) +
  theme_bw() +
  theme(plot.title = element_text(size = 11))

#' 
#' Accidents by hour:
#' 
## ----echo = T------------------------------------------------------------
byHour <- dataSet %>%
  group_by(Hour) %>%
  summarise(Accidents = n())
byHour$HourData <- as.numeric(byHour$Hour)
ggplot(byHour, aes(y = Accidents, x = HourData)) + 
  geom_line(color = "blue", size = .5) + 
  geom_point(color = "blue", size = 1.5) + 
  geom_point(color = "white", size = 1) + 
  scale_x_continuous(breaks = byHour$HourData-.5,
                   labels = byHour$Hour) +
  ggtitle('Belgrade, 2015: Traffic Accidents by Hour') + 
  xlab('Hour') +
  theme_bw() +
  theme(plot.title = element_text(size = 11))

#' 
#' Accident outcome vs. Month:
#' 
## ----echo = T------------------------------------------------------------
dataSet$MonthLabel <- month.abb[as.numeric(dataSet$Month)]
plot(table(dataSet$MonthLabel, dataSet$Outcome),
     main = 'Accident Outcomes per Month',
     col = "gold")

#' 
#' No pattern seems to be present:
#' 
## ----echo = T, results = 'asis'------------------------------------------
testAccMonth <- as.matrix(table(dataSet$MonthLabel, dataSet$Outcome))
kable(testAccMonth)

#' 
#' To confirm, ${\chi}^2$-test for contingency tables:
#' 
## ----echo = T, results = 'asis'------------------------------------------
chisq.test(testAccMonth, 
           simulate.p.value = T)

#' 
#' When do the fatal accidents take place?
#' 
## ----echo = T, results = 'asis'------------------------------------------
fatalSet <- dataSet %>% 
  filter(Outcome == 'Death') %>% 
  group_by(Hour) %>% 
  summarise(Accidents = n()) %>% 
  t()
colnames(fatalSet) <- fatalSet[1,]
fatalSet <- fatalSet[-1,]
kable(t(fatalSet), caption = 'Fatal Accidents by Hour:')

#' 
#' Is there a pattern in the hourly distribution of the accident outcome?
#' 
## ----echo = T, results = 'asis'------------------------------------------
byHourSet <- dataSet %>%
  group_by(Hour, Outcome) %>% 
  tally() %>%
  mutate(Percent = round(n/sum(n)*100,2))
ggplot(data = byHourSet, 
       aes(x = Hour, y = Percent, color = Outcome, fill = Outcome)) +
  geom_bar(stat = "identity", position = "stack", width = .5) + 
  scale_fill_brewer(palette = "Blues") +
  scale_color_brewer(palette = "Blues") +
  theme_bw()

#' 
#' Any indication of a relationship?
#' We already know that there will missing data for fatal accidents:
#' 
## ----echo = T------------------------------------------------------------
byHourSet <- dataSet %>%
  filter(!(Outcome == 'Death')) %>% 
  group_by(Hour, Outcome) %>% 
  tally() %>%
  spread(key = Outcome, value = n) %>% 
  ungroup() %>% dplyr::select(-Hour)
  chisq.test(byHourSet, 
             simulate.p.value = T)

#' 
#' Hm.
#' 
## ----echo = T------------------------------------------------------------
byHourSet <- dataSet %>%
  group_by(Hour, Outcome) %>% 
  tally() %>%
  mutate(Percent = round(n/sum(n)*100,2)) %>%
  filter(Outcome == 'Injury')
ggplot(data = byHourSet, 
       aes(x = as.numeric(Hour), y = Percent)) +
  geom_path(color = 'blue') +
  geom_point(size = 1.5, color = 'blue') +
  geom_point(size = 1, color = 'white') +
  xlab('Hour') + ylim(20,35) +
  ggtitle('Percent of Accidents w. Injuries per Hour') +
  scale_x_continuous(breaks = as.numeric(byHourSet$Hour),
                     labels = as.character(0:23)) +
  theme_bw()

#' 
#' Let's inspect the distribution of traffic accidents per day:
#' 
## ----echo = T------------------------------------------------------------
dataSet <- unite(data = dataSet,
                 col = Date,
                 Year, Month, Day,
                 sep = "-")


#' 
#' Check whether there are any days with no accidents that are not in December 2015. for which we have no data:
#' 
## ----echo = T------------------------------------------------------------
distData <- dataSet %>% 
  group_by(Date) %>%
  summarise(Frequency = n())
distData$Date <- as.Date(distData$Date)
dates2015 <- seq(as.Date("2015/1/1"), as.Date("2015/12/31"), "days")
w <- which(dates2015 %in% distData$Date)
obs <- rep(0, length(dates2015))
obs[w] <- distData$Frequency
distData <- data.frame(
  Date = dates2015,
  Frequency = obs)
length(which(distData$Frequency == 0)) # December data, right

#' 
## ----echo = T------------------------------------------------------------
which(distData$Frequency == 0) # December data, right

#' 
## ----echo = T------------------------------------------------------------
distData <- distData[distData$Frequency > 0, ]
ggplot(distData, aes(x = Frequency)) +
  geom_bar(stat = 'count', fill = "blue", alpha = .35, width = .5) +
  xlab("Number of Accidents Per Day") + ylab("Frequency") + 
  ggtitle('Belgrade, 2015: Traffic Accidents Daily Frequency') +
theme_bw()